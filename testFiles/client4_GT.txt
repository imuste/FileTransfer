This is a P2P software that used to be very popular. The idea is that we have a notion of a server but it only does coordination and the clients all exchange chunks of the file that they all need.
You have a tracker (the server) and if a client wants a file, it asks the server which keeps track of everyone else interested in transferring that file. It will give the client 50 IP addresses of peers and gives chunk availability info that shows who has what chunks. Then the client can start participating in the P2P transferring. These transfers only happen during the download process because this used to take hours and peers helping each other only benefits you during the download. After it is done, a client has no incentive to keep sharing.
In designing who a client gives and gets chunks from, we have to consider which chunks it wants to request and who to serve chunks to. We want to request chunks that we don't have yet and we want to use the rarest first strategy which means we want to get the rarest chunks first before they disappear. You also want even distribution of chunks in case that only a few others have certain chunks which when they're done, disappear which causes the chunks become less and less available.
We want to consider who to serve, so if we have a rare chunk and we get a request for it, we can't serve everyone. So we need to choose who to server this chunk to. We also don't want to server too many nodes at the same time because this would lower the upload bandwidth that a peer would get from us since it's split among everyone that we're sending to. So we want to choose peers that are also serving us and we prioritize the ones that have faster bandwidth because that serves us as well. So we pick a small number of nodes that serve us and that are the fastest.
We have 6 nodes: (1) with a rare chunk, (2) with nothing, and (3-6) with some random chunks. In this case, if we're node 1, we would pick 3 nodes which would be the two fastest from nodes (3-6) and the third one would be picked randomly. This gives the new node with no chunks a randomized chance of getting picked. This can also be good for us in case that that node turns out to be really good which can give a relationship with that node that can serve us in the future. So in terms of serving, we use a tit for tat strategy where we prioritize nodes serving us and fast ones. Then this will turn out that nodes will end up sharing with nodes of equal bandwidth.
When you pick nodes this is called unchocked those nodes and the random one is optimistic unchocked and the ones we don't pick are chocked. So in a stable state, the slowest nodes are the last ones to get the full download because the connections between nodes trickles down to the slower nodes.
The tracker has a hash map of the chunks and what they has to which can be used to confirm correctness of the info we're getting. The picking of nodes from random selection are nodes that aren't currently serving us. From nodes that are serving us, we will calculate the time it takes based on size and then we can see which peers are faster and rank those higher for the next round.